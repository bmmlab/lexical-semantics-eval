{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34b06582-ba94-48c2-a4b9-061db7f14af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import csv\n",
    "import math\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from transformers import logging\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "logging.set_verbosity_error() # turn off annoying model initialisation warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a14c96c4-adbd-4210-aa49-508a5dd44d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])?  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing done.\n"
     ]
    }
   ],
   "source": [
    "# Reset variables and recover memory\n",
    "gc.collect()\n",
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e75d6eb8-f1fd-43c8-af42-9383e4a02eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class similarity_analysis(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = list(self.model_embed_storage.keys())\n",
    "        self.datasets = list(self.dataset_storage.keys())\n",
    "        self.generate_vocab_set()\n",
    "        print('Available models:')\n",
    "        print(self.models)\n",
    "        print('Available datasets:')\n",
    "        print(self.datasets)\n",
    "        return(None)\n",
    "    \n",
    "    # Define file location variables\n",
    "    folder_loc= 'D:/Study and Projects/School Work/Year 25 - PhD 1/Data//'\n",
    "    model_loc = 'Word Embeddings//'\n",
    "    sent_loc = 'Sentence Embeddings//'\n",
    "    dataset_loc = 'Word Similarity Data/Collection of Word Similarity Benchmarks//'\n",
    "\n",
    "    model_files = {'glove':'Glove Word Embeddings/glove.840B.300d.mini.txt',\n",
    "                   'CW_vectors':'Collobert and Weston Vectors/embeddings.txt',\n",
    "                   'dm_vectors':'Distributional Memory Embeddings/dm_vectors_mini.txt',\n",
    "                   'fasttext_wiki+giga':'FastText Skipgram wiki+giga/model_mini.txt',\n",
    "                   'conceptnet':'ConceptNet Embeddings/numberbatch-en-mini.txt',\n",
    "                   'word2vec_skip':'Word2vec Skipgram CoNLL17/model_mini.txt',\n",
    "                   'lexvec':'LexVec Embeddings/lexvec_wiki+newscrawl_300d_mini.txt',\n",
    "                   'bert':'bert-base-uncased',\n",
    "                   'elmo':'Elmo Embeddings/elmo_mini.txt',\n",
    "                   'gensim_skip':'Gensim Skipgram wiki+giga/model_mini.txt',\n",
    "                   'electra':'electra-base-discriminator',\n",
    "                   'wordnet':'WordNet Word Embeddings/wn2vec_mini.txt',\n",
    "                   'gensim_cbow':'Gensim CBoW giga/2010_mini.txt',\n",
    "                   'gpt2':'gpt2',\n",
    "                   'bert_context':'simverb_bert_context.txt'\n",
    "                  }\n",
    "        \n",
    "    dataset_files = {'RG65':'EN-RG-65.txt',\n",
    "                     'YP130':'EN-YP-130.txt',\n",
    "                     'MTurk287':'EN-MTurk-287.txt',\n",
    "                     'MTurk213':'EN-MTurk-213-no-prop.txt',\n",
    "                     'MTurk771':'EN-MTurk-771.txt',\n",
    "                     'WS198':'EN-WS-198-SIM-no-prop.txt',\n",
    "                     'RW':'EN-RW-STANFORD.txt',\n",
    "                     'MEN':'EN-MEN-TR-3k.txt',\n",
    "                     'SimVerb':'EN-SimVerb-3500.txt',\n",
    "                     'SimLex':'EN-SIMLEX-999.txt',\n",
    "                     'SimLexN':'EN-SIMLEX-999-NOUN.txt',\n",
    "                     'SimLexV':'EN-SIMLEX-999-VERB.txt',\n",
    "                     'SimLexA':'EN-SIMLEX-999-ADJ.txt',\n",
    "                     'SimVerb_na':'SimVerb3360_no_ant.txt',\n",
    "                     'SimVerb_nax':'SimVerb3340_no_ant_aux.txt'\n",
    "                    }\n",
    "    \n",
    "    # these storage vectors are loading in the embeddings or datasets directly as numpy arrays\n",
    "    model_embed_storage = {'CW_vectors':[], 'dm_vectors':[],\n",
    "                           'gensim_cbow':[], 'gensim_skip':[], 'word2vec_skip':[],\n",
    "                           'glove':[], 'fasttext_wiki+giga':[], 'lexvec':[], 'elmo':[],\n",
    "                           'conceptnet':[], 'wordnet':[], \n",
    "                           'bert':[], 'gpt2':[], 'electra':[], 'bert_context':[]}\n",
    "     \n",
    "    dataset_storage = {'RG65':[], 'YP130':[], 'MTurk287':[], 'MTurk213':[], 'WS198':[], 'MTurk771':[], \n",
    "                       'RW':[], 'MEN':[], 'SimLex':[], 'SimLexN':[], 'SimLexV':[], 'SimLexA':[], 'SimVerb':[], 'SimVerb_na':[], 'SimVerb_nax':[]}\n",
    "    \n",
    "    # these storage vectors are for dictoniaries with pre-computed similarities\n",
    "    model_sim_storage = {'CW_vectors':{}, 'dm_vectors':{},\n",
    "                         'gensim_cbow':{}, 'gensim_skip':{}, 'word2vec_skip':{}, \n",
    "                         'glove':{}, 'fasttext_wiki+giga':{}, 'lexvec':{}, 'elmo':{}, \n",
    "                         'conceptnet':{}, 'wordnet':{}, \n",
    "                         'bert':{}, 'gpt2':{}, 'electra':{}, 'bert_context':{}}\n",
    "    \n",
    "    dataset_sim_storage = {'RG65':{}, 'YP130':{}, 'MTurk287':{}, 'MTurk213':{}, 'WS198':{}, 'MTurk771':{}, \n",
    "                           'RW':{}, 'MEN':{}, 'SimLex':{}, 'SimLexN':{}, 'SimLexV':{}, 'SimLexA':{}, 'SimVerb':{}, 'SimVerb_na':{}, 'SimVerb_nax':{}}\n",
    "    \n",
    "    transformers = {'bert','electra','xlm'}\n",
    "    \n",
    "    unique_vocab_set = []\n",
    "    \n",
    "    rare_word_loc = folder_loc+'Corpus Data/Key vocab/Rare_Words_substitutions.csv'\n",
    "    RW_mod_pd = pd.read_csv(rare_word_loc, index_col=0, header=None, on_bad_lines='skip')\n",
    "    RW_mod_dict = RW_mod_pd.to_dict()[1] \n",
    "    \n",
    "    \n",
    "    # Generate full set of unique vocabulary needed\n",
    "    def generate_vocab_set(self):\n",
    "        full_vocab_set = []\n",
    "        for dataset in self.dataset_storage.keys():\n",
    "            if len(self.dataset_storage[dataset])==0: # load dataset if needed\n",
    "                self.import_dataset(dataset)\n",
    "            wordset = self.dataset_storage[dataset][0] # get set of words in that dataset\n",
    "            for wordpair in wordset:\n",
    "                full_vocab_set.append(wordpair[0])\n",
    "                full_vocab_set.append(wordpair[1])\n",
    "        unique_vocab_set = list(set(full_vocab_set)) # unique words only\n",
    "        unique_vocab_set.sort()\n",
    "        self.unique_vocab_set = unique_vocab_set\n",
    "        print('Total tested words:',len(full_vocab_set))\n",
    "        print('Unique tested words:',len(unique_vocab_set))\n",
    "        \n",
    "    \n",
    "    # Simple function to print a single model\n",
    "    def print_model(self, model_name):\n",
    "        \"\"\" string -> None\n",
    "        Print a summary of the embeddings for a given model.\n",
    "        \"\"\"\n",
    "        if self.model_embed_storage[model_name]==0:\n",
    "            print('not loaded')\n",
    "        else:\n",
    "            display(self.model_embed_storage[model_name][0])\n",
    "    \n",
    "    \n",
    "    # Function to import all models into the storage dictionary\n",
    "    def import_all_models(self):\n",
    "        \"\"\" None -> None\n",
    "        Imports all models into the model_embed_storage dictionary.\n",
    "        \"\"\"\n",
    "        for model in self.model_embed_storage:\n",
    "            self.import_model(model)\n",
    "            \n",
    "            \n",
    "    # Function to load a specific word embedding model\n",
    "    def import_model(self, model_name):\n",
    "        \"\"\" string -> None\n",
    "        Imports an embedding model, storing it in the model_embed_storage dictionary.\n",
    "        \"\"\"\n",
    "        if len(self.model_embed_storage[model_name])==0: #only if its not already loaded\n",
    "            if model_name in self.transformers: # for transformer models\n",
    "                file_loc = self.model_files[model_name]\n",
    "                filename = self.folder_loc+self.sent_loc+file_loc\n",
    "                config_state = AutoConfig.from_pretrained(filename, output_hidden_states=True) # get hidden states\n",
    "                tokenizer = AutoTokenizer.from_pretrained(filename)\n",
    "                model = AutoModel.from_pretrained(filename, config=config_state)\n",
    "                self.model_embed_storage[model_name] = (model,tokenizer) # need the model and tokeniser\n",
    "           \n",
    "            elif model_name == 'gpt2':\n",
    "                file_loc = self.model_files[model_name]\n",
    "                filename = self.folder_loc+self.sent_loc+file_loc\n",
    "                tokenizer = GPT2Tokenizer.from_pretrained(filename)\n",
    "                model = GPT2LMHeadModel.from_pretrained(filename)\n",
    "                self.model_embed_storage[model_name] = (model,tokenizer)\n",
    "                               \n",
    "           # elif model_name=='gensim_skip':\n",
    "           #     file_loc = self.model_files[model_name]\n",
    "           #     filename = self.folder_loc+self.model_loc+file_loc\n",
    "           #     self.model_embed_storage[model_name] = [pd.read_csv(filename, index_col=0, header=None, sep=',', on_bad_lines='skip', encoding='latin-1')]\n",
    "                                                  \n",
    "            else: # for static word embedding models\n",
    "                file_loc = self.model_files[model_name]\n",
    "                filename = self.folder_loc+self.model_loc+file_loc\n",
    "                with open(filename) as file:\n",
    "                    lines = [line.rstrip('\\n') for line in file]\n",
    "\n",
    "                model_dict = {} # word dictionary for specific model\n",
    "                for line in lines:\n",
    "                    word_list = line.split()\n",
    "                    word = word_list[0]\n",
    "                    if word in self.unique_vocab_set: # only need the words we will use for testing\n",
    "                        embedding_list = [float(x) for x in word_list[1:-1]]\n",
    "                        embedding_np = np.array(embedding_list)\n",
    "                        model_dict[word] = embedding_np\n",
    "                    else:\n",
    "                        continue\n",
    "                \n",
    "                self.model_embed_storage[model_name] = model_dict # store model dictionary in the dictionary for all the models\n",
    "        \n",
    "            print(model_name+' loaded')\n",
    "            \n",
    "    \n",
    "    # Function to load word similarity data for specified dataset\n",
    "    def import_dataset(self, dataset_name):\n",
    "        \"\"\" string -> None\n",
    "        Imports a dataset, storing a value of the form (list, numpy_array) in the dataset_storage dictionary.\n",
    "        \"\"\"\n",
    "        if len(self.dataset_storage[dataset_name])==0: # if dataset not yet loaded\n",
    "            file_loc = self.dataset_files[dataset_name]\n",
    "            filename = self.folder_loc+self.dataset_loc+file_loc\n",
    "            with open(filename) as file:\n",
    "                lines = file.readlines()\n",
    "\n",
    "            wordpairs = [None]*len(lines) # initialise storage\n",
    "            ratings = [None]*len(lines)\n",
    "            i=0\n",
    "            for line in lines:\n",
    "                line = line.strip() # remove new line chars\n",
    "                wordpairs[i] = line.split() # split at any whitespace chars\n",
    "                ratings[i] = float(wordpairs[i][2])\n",
    "                i=i+1\n",
    "            ratings = np.array(ratings)\n",
    "\n",
    "            self.dataset_storage[dataset_name] = (wordpairs, ratings)\n",
    "            #print(dataset_name+' loaded')\n",
    "        \n",
    "    \n",
    "    # Function to get the embedding for a specific word, given a model\n",
    "    def get_word_embed(self, model_name, word, layer, comp_method):\n",
    "        \"\"\" string, string, integer, string -> numpy_array, boolean\n",
    "        Gets the word embedding for a specied model and word. Also takes a 'layer' argument which\n",
    "        specifies which layer of the hidden layer is extracted from transformer models.\n",
    "        The 'comp_method' argument specifies the method for extracting the word emedding.\n",
    "        \"\"\"\n",
    "        self.import_model(model_name)\n",
    "        model = self.model_embed_storage[model_name]\n",
    "        RW_set = self.RW_mod_pd.index.values\n",
    "        missed = False\n",
    "        \n",
    "        if model_name == 'gpt2': # gpt2 case as its structure is different to BERT\n",
    "            model_main = model[0]\n",
    "            tokenizer = model[1] # transformers need a tokenizer as well\n",
    "            encoded_input = tokenizer.encode(word, add_prefix_space=True, return_tensors='pt')\n",
    "            word_embedding_raw = model_main.transformer.wte.weight[encoded_input,:].detach().numpy()[0][0]\n",
    "            word_embedding = word_embedding_raw.reshape(-1)\n",
    "        \n",
    "        elif model_name in self.transformers: # for BERT-like transformer models\n",
    "            model_main = model[0]\n",
    "            tokenizer = model[1]\n",
    "            encoded_input = tokenizer(word, return_tensors='pt') #pt = pytorch\n",
    "            model_output = model_main(**encoded_input)\n",
    "            word_embedding_raw = model_output.hidden_states[layer].detach().numpy()[0]\n",
    "                \n",
    "            # embeddings depend on the comp_method chosen\n",
    "            if comp_method=='mean': # take the mean of all tokens\n",
    "                word_embedding = word_embedding_raw.mean(axis=0)\n",
    "            elif comp_method=='cls': # use the 'CLS' token\n",
    "                word_embedding = word_embedding_raw[0]\n",
    "            elif comp_method=='decontext': # take the mean of word tokens only\n",
    "                word_embedding = word_embedding_raw[1:-1].mean(axis=0)\n",
    "                \n",
    "        else: # for static word embedding models\n",
    "            embed_dim = model['man'].shape[0] # get embedding length\n",
    "            try:\n",
    "                alt_word = self.RW_mod_dict[word] # alterantive word for RW dataset (similar meaning)\n",
    "            except:\n",
    "                alt_word = 0 # no alt word available\n",
    "            \n",
    "            word_list = model.keys() # list of all words in the current model\n",
    "            if word in word_list:\n",
    "                word_embed = model[word] # get embedding from pandas array\n",
    "            elif alt_word!=0 and alt_word in word_list: # try alt word if one is defined\n",
    "                #print('substituting '+alt_word)\n",
    "                word_embed = model[alt_word]\n",
    "            elif word.capitalize() in word_list: # see if capitalised is in there\n",
    "                word_embed = model[word.capitalize()]\n",
    "            elif word.lower() in word_list: # see if lower case is in there\n",
    "                word_embed = model[word.lower()]\n",
    "            elif word[0:-1] in word_list: # see if non-plural is there\n",
    "                word_embed = model[word[0:-1]]\n",
    "            elif word[-2:]=='ed' and word[0:-2] in word_list: # see if non-past tense is there\n",
    "                word_embed = model[word[0:-2]]\n",
    "            elif word[-3:]=='ing' and word[0:-3] in word_list: # see if non-infinitive form is there\n",
    "                word_embed = model[word[0:-3]]\n",
    "            else: # if the word can't be found in the model\n",
    "                #print('missing '+word)\n",
    "                word_embed = np.random.rand(1,100)[0] # random embedding\n",
    "                missed = True\n",
    "                \n",
    "            word_embedding = np.array(word_embed)\n",
    " \n",
    "        return(word_embedding, missed)\n",
    "    \n",
    "    \n",
    "    # Function to compute the similarities of all word pairs from a given database, for a given model\n",
    "    def compute_model_sims(self, model_name, dataset_name, layer, comp_method):\n",
    "        \"\"\" string, string, integer, string -> float_list\n",
    "        Returns a list of similarities for all word pairs in a specified dataset, using a specified model.\n",
    "        \"\"\"\n",
    "        self.import_dataset(dataset_name) # load dataset if needed\n",
    "        dataset_words = self.dataset_storage[dataset_name][0] # word pairs in [0]\n",
    "        embed_sims = [None]*len(dataset_words)\n",
    "        i=0\n",
    "        for word_pair in dataset_words:\n",
    "            word_embed_1,miss_1 = self.get_word_embed(model_name, word_pair[0], layer, comp_method)\n",
    "            word_embed_2,miss_2 = self.get_word_embed(model_name, word_pair[1], layer, comp_method)\n",
    "            if miss_1==True or miss_2==True:\n",
    "                embed_sims[i] = math.nan # return NaN if either word is missing\n",
    "            else:\n",
    "                embed_sims[i] = self.cosine_sim(word_embed_1, word_embed_2)\n",
    "            i=i+1\n",
    "        return(embed_sims)\n",
    "    \n",
    "    \n",
    "    # Function to calculate cosine similarity between two embeddings\n",
    "    def cosine_sim(self, embed_1, embed_2):\n",
    "        \"\"\" numpy_array, numpy_array -> float\n",
    "        Returns the cosine similarity (-1 to 1) between two embeddings, inputted as vectors.\n",
    "        \"\"\"\n",
    "        if np.dot(embed_1,embed_2) == 0:\n",
    "            similarity = 0 # don't normalise if similarity is zero\n",
    "        else:\n",
    "            similarity = np.dot(embed_1,embed_2)/(np.linalg.norm(embed_1)*np.linalg.norm(embed_2))\n",
    "        return(similarity)\n",
    "       \n",
    "    \n",
    "    # Function to compute the correlation between model and dataset embedding similarities\n",
    "    def compute_embed_correls(self, model_name, dataset_name, layer, comp_method):\n",
    "        \"\"\" string, string, int, string -> (float, float)\n",
    "        Computes the pearson_r and spearman_r between word similarities for a dataset and model.\n",
    "        \"\"\"\n",
    "        self.import_dataset(dataset_name) # load model and dataset if needed\n",
    "        self.import_model(model_name)\n",
    "        model_sims = self.compute_model_sims(model_name, dataset_name, layer, comp_method)\n",
    "        dataset_sims = self.dataset_storage[dataset_name][1] # similarities stored in [1]\n",
    "        \n",
    "        model_masked = np.ma.masked_invalid(model_sims) # get mask to avoid NaN values\n",
    "        dataset_masked = np.ma.masked_invalid(dataset_sims)\n",
    "        full_mask = (~model_masked.mask & ~dataset_masked.mask) # combine masks for model and dataset similarities\n",
    "        pearson_r = np.corrcoef(model_masked[full_mask], dataset_masked[full_mask])[0,1] # correlation with masks\n",
    "        spearman_r, p = spearmanr(model_masked[full_mask], dataset_masked[full_mask])\n",
    "        print('missing words: '+str(len(full_mask)-sum(full_mask))+' out of '+str(len(full_mask)))\n",
    "        \n",
    "        return(pearson_r, spearman_r)\n",
    "    \n",
    "    \n",
    "    # Function to calculate the correlation between model and experimental similarities\n",
    "    def model_vs_data(self, model_name, dataset_name, layer=0, comp_method='mean'):\n",
    "        \"\"\" string, string, int, string -> None\n",
    "        Prints the correlation between the experimental and calculated similarities for a given\n",
    "        model and dataset. Requires layer and comp_method to be specified.\n",
    "        \"\"\"\n",
    "        correlations = self.compute_embed_correls(model_name, dataset_name, layer, comp_method)\n",
    "        print('evaluating '+model_name+' against '+dataset_name)\n",
    "        print('pearson: {:.3f}'.format(correlations[0]), '\\nspearman: {:.3f}\\n'.format(correlations[1]))\n",
    "        \n",
    "        \n",
    "    # Store similarities in dictionaries for future use\n",
    "    def store_similarities(self, model_name, dataset_name):\n",
    "        dataset_vocab = self.dataset_storage[dataset_name][0] # get dataset vocab\n",
    "        model_sims = self.compute_model_sims(model_name, dataset_name, layer=12, comp_method='decontext')\n",
    "        i=0\n",
    "        for word_pair in dataset_vocab:\n",
    "            word_pair_str = word_pair[0]+' '+word_pair[1] # word pair as string for dictionary storage\n",
    "            self.dataset_sim_storage[dataset_name][word_pair_str] = dataset_vocab[i][2] # store experimental similarity from dataset\n",
    "            self.model_sim_storage[model_name][word_pair_str] = model_sims[i] # store model-based similarity            \n",
    "            i=i+1\n",
    "        #print('Similarities for '+model_name+' with '+dataset_name+' saved')\n",
    "        \n",
    "        \n",
    "    # Bootstrap a set of draws for a given dataset and model\n",
    "    def single_bootstrap(self, model_name, dataset, layer=12, comp_method='decontext'):\n",
    "        self.store_similarities(model_name, dataset)\n",
    "\n",
    "        # Generate bootstrap sample\n",
    "        n = len(self.dataset_sim_storage[dataset].keys()) # size of vocab set\n",
    "        index_list = np.arange(0,n)\n",
    "        vocab_pair_list = list(self.dataset_sim_storage[dataset].keys())\n",
    "        rd_indices = np.random.choice(index_list,n) # get random indices for choosing vocab\n",
    "        rd_vocab_model_sims = np.zeros(n)\n",
    "        rd_vocab_exper_sims = np.zeros(n)\n",
    "        i=0\n",
    "        for index in rd_indices:\n",
    "            rd_vocab = vocab_pair_list[index] # get random vocab pair\n",
    "            rd_vocab_model_sims[i] = self.model_sim_storage[model_name][rd_vocab] # get model similarity\n",
    "            rd_vocab_exper_sims[i] = self.dataset_sim_storage[dataset][rd_vocab] # get experimental similarity\n",
    "            i=i+1\n",
    "\n",
    "        # Compute correlations\n",
    "        rd_vocab_model_sims_msk = np.ma.masked_invalid(rd_vocab_model_sims) # get mask to avoid NaN values\n",
    "        rd_vocab_exper_sims_msk = np.ma.masked_invalid(rd_vocab_exper_sims)\n",
    "        full_mask = (~rd_vocab_model_sims_msk.mask & ~rd_vocab_exper_sims_msk.mask) # combine masks for model and dataset similarities       \n",
    "        pearson_r = np.corrcoef(rd_vocab_model_sims[full_mask], rd_vocab_exper_sims[full_mask])[0,1]\n",
    "        spearman_r, p = spearmanr(rd_vocab_model_sims[full_mask], rd_vocab_exper_sims[full_mask])\n",
    "        return(pearson_r, spearman_r)\n",
    "    \n",
    "    \n",
    "    # Compute a series of bootstrap samples for a given model and dataset\n",
    "    def set_of_bootstraps(self, model_name, dataset, num_samples=100, layer=12, comp_method='decontext'):\n",
    "        corr_samples_pearson = []\n",
    "        corr_samples_spearman = []\n",
    "        for run in np.arange(0,num_samples):\n",
    "            correlations = sim.single_bootstrap(model_name, dataset, layer, comp_method)\n",
    "            corr_samples_pearson.append(correlations[0])\n",
    "            corr_samples_spearman.append(correlations[1])\n",
    "            \n",
    "        return(corr_samples_pearson, corr_samples_spearman)\n",
    "    \n",
    "    \n",
    "    def plot_model_bootstraps(self, dataset_name, num_samples=100):\n",
    "        mean_correlations = np.array([])\n",
    "        CI_95_percents = np.array([])\n",
    "        \n",
    "        # compute mean and std dev of correlations between all models and specified dataset\n",
    "        for model in sim.models[0:-3]:\n",
    "            pearson_corrs, spearman_corrs = sim.set_of_bootstraps(model, dataset_name, num_samples)\n",
    "            mean_correlations = np.append(mean_correlations, np.mean(spearman_corrs))\n",
    "            pt_5, pt_95 = np.percentile(spearman_corrs, [5,95]) # get percentiles for 95% CI\n",
    "            CI_95_percents = np.append(CI_95_percents, (pt_95-pt_5)/2)\n",
    "            print('finished '+model)\n",
    "        \n",
    "        # plot barplot\n",
    "        fig, ax = plt.subplots(figsize=(14,4))\n",
    "        ax.bar(x=sim.models[0:-3], #x-coordinates of bars\n",
    "               height=mean_correlations, #height of bars\n",
    "               yerr=CI_95_percents, #error bar width\n",
    "               capsize=6) #length of error bar caps\n",
    "        plt.show()\n",
    "        \n",
    "        return(mean_correlations, CI_95_percents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "842428e7-2043-43b0-8e91-2ec454a3eb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tested words: 37808\n",
      "Unique tested words: 5701\n",
      "Available models:\n",
      "['CW_vectors', 'dm_vectors', 'gensim_cbow', 'gensim_skip', 'word2vec_skip', 'glove', 'fasttext_wiki+giga', 'lexvec', 'elmo', 'conceptnet', 'wordnet', 'bert', 'gpt2', 'electra', 'bert_context']\n",
      "Available datasets:\n",
      "['RG65', 'YP130', 'MTurk287', 'MTurk213', 'WS198', 'MTurk771', 'RW', 'MEN', 'SimLex', 'SimLexN', 'SimLexV', 'SimLexA', 'SimVerb', 'SimVerb_na', 'SimVerb_nax']\n"
     ]
    }
   ],
   "source": [
    "sim = similarity_analysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f5bc8657-090d-443f-90ca-d1ec16c0cfe1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CW_vectors loaded\n",
      "dm_vectors loaded\n",
      "gensim_cbow loaded\n",
      "gensim_skip loaded\n",
      "word2vec_skip loaded\n",
      "glove loaded\n",
      "fasttext_wiki+giga loaded\n",
      "lexvec loaded\n",
      "elmo loaded\n",
      "conceptnet loaded\n",
      "wordnet loaded\n",
      "bert loaded\n",
      "gpt2 loaded\n",
      "electra loaded\n",
      "bert_context loaded\n"
     ]
    }
   ],
   "source": [
    "sim.import_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6127f40-e1dd-4c39-9a70-a62ab7273465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing words: 4 out of 3367\n",
      "evaluating bert_context against SimVerb_na\n",
      "pearson: 0.447 \n",
      "spearman: 0.442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sim.model_vs_data('bert_context','SimVerb_na', layer=0, comp_method='decontext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "ecd59c54-3f9f-4bb9-ba5d-f431da026558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished CW_vectors\n",
      "finished dm_vectors\n",
      "finished gensim_cbow\n",
      "finished gensim_skip\n",
      "finished word2vec_skip\n",
      "finished glove\n",
      "finished fasttext_wiki+giga\n",
      "finished lexvec\n",
      "finished elmo\n",
      "finished conceptnet\n",
      "finished wordnet\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "means, errors = sim.plot_model_bootstraps('MTurk213', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "c04dd645-a051-4ddf-b447-d24b23940a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished CW_vectors\n",
      "finished dm_vectors\n",
      "finished gensim_cbow\n",
      "finished gensim_skip\n",
      "finished word2vec_skip\n",
      "finished glove\n",
      "finished fasttext_wiki+giga\n",
      "finished lexvec\n",
      "finished elmo\n",
      "finished conceptnet\n",
      "finished wordnet\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "means, errors = sim.plot_model_bootstraps('SimVerb', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "db9576d2-7d36-4432-9d74-35f9640d4070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished CW_vectors\n",
      "finished dm_vectors\n",
      "finished gensim_cbow\n",
      "finished gensim_skip\n",
      "finished word2vec_skip\n",
      "finished glove\n",
      "finished fasttext_wiki+giga\n",
      "finished lexvec\n",
      "finished elmo\n",
      "finished conceptnet\n",
      "finished wordnet\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "means, errors = sim.plot_model_bootstraps('SimLex', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a0a01d37-6d75-418a-a514-a82466ca16ca",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CW_vectors loaded\n",
      "missing words: 0 out of 65\n",
      "evaluating CW_vectors against RG65\n",
      "pearson: 0.469 \n",
      "spearman: 0.467\n",
      "\n",
      "dm_vectors loaded\n",
      "missing words: 0 out of 65\n",
      "evaluating dm_vectors against RG65\n",
      "pearson: 0.539 \n",
      "spearman: 0.422\n",
      "\n",
      "gensim_cbow loaded\n",
      "missing words: 0 out of 65\n",
      "evaluating gensim_cbow against RG65\n",
      "pearson: 0.695 \n",
      "spearman: 0.680\n",
      "\n",
      "gensim_skip loaded\n",
      "missing words: 0 out of 65\n",
      "evaluating gensim_skip against RG65\n",
      "pearson: 0.735 \n",
      "spearman: 0.714\n",
      "\n",
      "word2vec_skip loaded\n",
      "missing words: 0 out of 65\n",
      "evaluating word2vec_skip against RG65\n",
      "pearson: 0.696 \n",
      "spearman: 0.698\n",
      "\n",
      "missing words: 0 out of 65\n",
      "evaluating glove against RG65\n",
      "pearson: 0.771 \n",
      "spearman: 0.771\n",
      "\n",
      "fasttext_wiki+giga loaded\n",
      "missing words: 0 out of 65\n",
      "evaluating fasttext_wiki+giga against RG65\n",
      "pearson: 0.741 \n",
      "spearman: 0.711\n",
      "\n",
      "lexvec loaded\n",
      "missing words: 0 out of 65\n",
      "evaluating lexvec against RG65\n",
      "pearson: 0.760 \n",
      "spearman: 0.747\n",
      "\n",
      "elmo loaded\n",
      "missing words: 0 out of 65\n",
      "evaluating elmo against RG65\n",
      "pearson: 0.721 \n",
      "spearman: 0.717\n",
      "\n",
      "conceptnet loaded\n",
      "missing words: 0 out of 65\n",
      "evaluating conceptnet against RG65\n",
      "pearson: 0.903 \n",
      "spearman: 0.924\n",
      "\n",
      "wordnet loaded\n",
      "missing words: 0 out of 65\n",
      "evaluating wordnet against RG65\n",
      "pearson: 0.720 \n",
      "spearman: 0.560\n",
      "\n",
      "bert loaded\n",
      "missing words: 0 out of 65\n",
      "evaluating bert against RG65\n",
      "pearson: 0.713 \n",
      "spearman: 0.762\n",
      "\n",
      "gpt2 loaded\n",
      "missing words: 0 out of 65\n",
      "evaluating gpt2 against RG65\n",
      "pearson: 0.633 \n",
      "spearman: 0.633\n",
      "\n",
      "electra loaded\n",
      "missing words: 0 out of 65\n",
      "evaluating electra against RG65\n",
      "pearson: 0.769 \n",
      "spearman: 0.787\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in sim.models:\n",
    "    sim.model_vs_data(model,'RG65', layer=0, comp_method='decontext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d6a932ae-140a-4278-bdd9-49c8dee93f67",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTurk287 loaded\n",
      "missing words: 1 out of 287\n",
      "evaluating CW_vectors against MTurk287\n",
      "pearson: 0.614 \n",
      "spearman: 0.587\n",
      "\n",
      "missing words: 23 out of 287\n",
      "evaluating gensim_cbow against MTurk287\n",
      "pearson: 0.651 \n",
      "spearman: 0.612\n",
      "\n",
      "missing words: 21 out of 287\n",
      "evaluating gensim_skip against MTurk287\n",
      "pearson: 0.699 \n",
      "spearman: 0.645\n",
      "\n",
      "missing words: 0 out of 287\n",
      "evaluating word2vec_skip against MTurk287\n",
      "pearson: 0.726 \n",
      "spearman: 0.701\n",
      "\n",
      "missing words: 0 out of 287\n",
      "evaluating glove against MTurk287\n",
      "pearson: 0.737 \n",
      "spearman: 0.688\n",
      "\n",
      "missing words: 21 out of 287\n",
      "evaluating fasttext_wiki+giga against MTurk287\n",
      "pearson: 0.709 \n",
      "spearman: 0.655\n",
      "\n",
      "missing words: 0 out of 287\n",
      "evaluating lexvec against MTurk287\n",
      "pearson: 0.697 \n",
      "spearman: 0.656\n",
      "\n",
      "missing words: 0 out of 287\n",
      "evaluating elmo against MTurk287\n",
      "pearson: 0.600 \n",
      "spearman: 0.585\n",
      "\n",
      "missing words: 0 out of 287\n",
      "evaluating conceptnet against MTurk287\n",
      "pearson: 0.767 \n",
      "spearman: 0.721\n",
      "\n",
      "missing words: 169 out of 287\n",
      "evaluating wordnet against MTurk287\n",
      "pearson: 0.491 \n",
      "spearman: 0.477\n",
      "\n",
      "missing words: 0 out of 287\n",
      "evaluating bert against MTurk287\n",
      "pearson: 0.636 \n",
      "spearman: 0.585\n",
      "\n",
      "missing words: 0 out of 287\n",
      "evaluating gpt2 against MTurk287\n",
      "pearson: 0.625 \n",
      "spearman: 0.582\n",
      "\n",
      "missing words: 0 out of 287\n",
      "evaluating electra against MTurk287\n",
      "pearson: 0.671 \n",
      "spearman: 0.651\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in sim.models:\n",
    "    sim.model_vs_data(model,'MTurk287', layer=0, comp_method='decontext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fdb30cd9-8206-4322-9cd4-6b14201f8667",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTurk213 loaded\n",
      "missing words: 1 out of 213\n",
      "evaluating CW_vectors against MTurk213\n",
      "pearson: 0.595 \n",
      "spearman: 0.559\n",
      "\n",
      "missing words: 6 out of 213\n",
      "evaluating gensim_cbow against MTurk213\n",
      "pearson: 0.664 \n",
      "spearman: 0.637\n",
      "\n",
      "missing words: 2 out of 213\n",
      "evaluating gensim_skip against MTurk213\n",
      "pearson: 0.709 \n",
      "spearman: 0.676\n",
      "\n",
      "missing words: 0 out of 213\n",
      "evaluating word2vec_skip against MTurk213\n",
      "pearson: 0.736 \n",
      "spearman: 0.692\n",
      "\n",
      "missing words: 0 out of 213\n",
      "evaluating glove against MTurk213\n",
      "pearson: 0.756 \n",
      "spearman: 0.704\n",
      "\n",
      "missing words: 2 out of 213\n",
      "evaluating fasttext_wiki+giga against MTurk213\n",
      "pearson: 0.719 \n",
      "spearman: 0.677\n",
      "\n",
      "missing words: 0 out of 213\n",
      "evaluating lexvec against MTurk213\n",
      "pearson: 0.698 \n",
      "spearman: 0.648\n",
      "\n",
      "missing words: 0 out of 213\n",
      "evaluating elmo against MTurk213\n",
      "pearson: 0.615 \n",
      "spearman: 0.591\n",
      "\n",
      "missing words: 0 out of 213\n",
      "evaluating conceptnet against MTurk213\n",
      "pearson: 0.792 \n",
      "spearman: 0.739\n",
      "\n",
      "missing words: 109 out of 213\n",
      "evaluating wordnet against MTurk213\n",
      "pearson: 0.489 \n",
      "spearman: 0.498\n",
      "\n",
      "missing words: 0 out of 213\n",
      "evaluating bert against MTurk213\n",
      "pearson: 0.658 \n",
      "spearman: 0.627\n",
      "\n",
      "missing words: 0 out of 213\n",
      "evaluating gpt2 against MTurk213\n",
      "pearson: 0.648 \n",
      "spearman: 0.604\n",
      "\n",
      "missing words: 0 out of 213\n",
      "evaluating electra against MTurk213\n",
      "pearson: 0.689 \n",
      "spearman: 0.680\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in sim.models:\n",
    "    sim.model_vs_data(model,'MTurk213', layer=0, comp_method='decontext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "617b730a-4a2e-41f1-a4e9-dbb0605622e7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WS353 loaded\n",
      "missing words: 0 out of 353\n",
      "evaluating CW_vectors against WS353\n",
      "pearson: 0.507 \n",
      "spearman: 0.498\n",
      "\n",
      "missing words: 14 out of 353\n",
      "evaluating dm_vectors against WS353\n",
      "pearson: 0.361 \n",
      "spearman: 0.299\n",
      "\n",
      "missing words: 0 out of 353\n",
      "evaluating gensim_cbow against WS353\n",
      "pearson: 0.622 \n",
      "spearman: 0.644\n",
      "\n",
      "missing words: 0 out of 353\n",
      "evaluating gensim_skip against WS353\n",
      "pearson: 0.639 \n",
      "spearman: 0.672\n",
      "\n",
      "missing words: 0 out of 353\n",
      "evaluating word2vec_skip against WS353\n",
      "pearson: 0.700 \n",
      "spearman: 0.711\n",
      "\n",
      "missing words: 0 out of 353\n",
      "evaluating glove against WS353\n",
      "pearson: 0.719 \n",
      "spearman: 0.722\n",
      "\n",
      "missing words: 0 out of 353\n",
      "evaluating fasttext_wiki+giga against WS353\n",
      "pearson: 0.660 \n",
      "spearman: 0.688\n",
      "\n",
      "missing words: 0 out of 353\n",
      "evaluating lexvec against WS353\n",
      "pearson: 0.635 \n",
      "spearman: 0.661\n",
      "\n",
      "missing words: 0 out of 353\n",
      "evaluating elmo against WS353\n",
      "pearson: 0.538 \n",
      "spearman: 0.542\n",
      "\n",
      "missing words: 0 out of 353\n",
      "evaluating conceptnet against WS353\n",
      "pearson: 0.753 \n",
      "spearman: 0.815\n",
      "\n",
      "missing words: 15 out of 353\n",
      "evaluating wordnet against WS353\n",
      "pearson: 0.469 \n",
      "spearman: 0.478\n",
      "\n",
      "missing words: 0 out of 353\n",
      "evaluating bert against WS353\n",
      "pearson: 0.601 \n",
      "spearman: 0.655\n",
      "\n",
      "missing words: 0 out of 353\n",
      "evaluating gpt2 against WS353\n",
      "pearson: 0.626 \n",
      "spearman: 0.665\n",
      "\n",
      "missing words: 0 out of 353\n",
      "evaluating electra against WS353\n",
      "pearson: 0.638 \n",
      "spearman: 0.690\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in sim.models:\n",
    "    sim.model_vs_data(model,'WS353', layer=0, comp_method='decontext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c7ac113d-90d3-49ec-a38f-33dd3df16425",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WS198 loaded\n",
      "missing words: 0 out of 198\n",
      "evaluating CW_vectors against WS198\n",
      "pearson: 0.606 \n",
      "spearman: 0.585\n",
      "\n",
      "missing words: 0 out of 198\n",
      "evaluating gensim_cbow against WS198\n",
      "pearson: 0.747 \n",
      "spearman: 0.737\n",
      "\n",
      "missing words: 0 out of 198\n",
      "evaluating gensim_skip against WS198\n",
      "pearson: 0.766 \n",
      "spearman: 0.770\n",
      "\n",
      "missing words: 0 out of 198\n",
      "evaluating word2vec_skip against WS198\n",
      "pearson: 0.762 \n",
      "spearman: 0.762\n",
      "\n",
      "missing words: 0 out of 198\n",
      "evaluating glove against WS198\n",
      "pearson: 0.801 \n",
      "spearman: 0.798\n",
      "\n",
      "missing words: 0 out of 198\n",
      "evaluating fasttext_wiki+giga against WS198\n",
      "pearson: 0.779 \n",
      "spearman: 0.782\n",
      "\n",
      "missing words: 0 out of 198\n",
      "evaluating lexvec against WS198\n",
      "pearson: 0.723 \n",
      "spearman: 0.725\n",
      "\n",
      "missing words: 0 out of 198\n",
      "evaluating elmo against WS198\n",
      "pearson: 0.727 \n",
      "spearman: 0.734\n",
      "\n",
      "missing words: 0 out of 198\n",
      "evaluating conceptnet against WS198\n",
      "pearson: 0.841 \n",
      "spearman: 0.844\n",
      "\n",
      "missing words: 5 out of 198\n",
      "evaluating wordnet against WS198\n",
      "pearson: 0.623 \n",
      "spearman: 0.571\n",
      "\n",
      "missing words: 0 out of 198\n",
      "evaluating bert against WS198\n",
      "pearson: 0.717 \n",
      "spearman: 0.753\n",
      "\n",
      "missing words: 0 out of 198\n",
      "evaluating gpt2 against WS198\n",
      "pearson: 0.734 \n",
      "spearman: 0.727\n",
      "\n",
      "missing words: 0 out of 198\n",
      "evaluating electra against WS198\n",
      "pearson: 0.734 \n",
      "spearman: 0.765\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in sim.models:\n",
    "    sim.model_vs_data(model,'WS198', layer=0, comp_method='decontext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "0bccb5dc-4982-4712-b022-50248ef1329b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MTurk771 loaded\n",
      "missing words: 0 out of 771\n",
      "evaluating CW_vectors against MTurk771\n",
      "pearson: 0.496 \n",
      "spearman: 0.496\n",
      "\n",
      "missing words: 3 out of 771\n",
      "evaluating dm_vectors against MTurk771\n",
      "pearson: 0.312 \n",
      "spearman: 0.216\n",
      "\n",
      "missing words: 1 out of 771\n",
      "evaluating gensim_cbow against MTurk771\n",
      "pearson: 0.570 \n",
      "spearman: 0.567\n",
      "\n",
      "missing words: 1 out of 771\n",
      "evaluating gensim_skip against MTurk771\n",
      "pearson: 0.600 \n",
      "spearman: 0.621\n",
      "\n",
      "missing words: 0 out of 771\n",
      "evaluating word2vec_skip against MTurk771\n",
      "pearson: 0.631 \n",
      "spearman: 0.641\n",
      "\n",
      "missing words: 0 out of 771\n",
      "evaluating glove against MTurk771\n",
      "pearson: 0.705 \n",
      "spearman: 0.715\n",
      "\n",
      "missing words: 1 out of 771\n",
      "evaluating fasttext_wiki+giga against MTurk771\n",
      "pearson: 0.613 \n",
      "spearman: 0.633\n",
      "\n",
      "missing words: 0 out of 771\n",
      "evaluating lexvec against MTurk771\n",
      "pearson: 0.640 \n",
      "spearman: 0.663\n",
      "\n",
      "missing words: 0 out of 771\n",
      "evaluating elmo against MTurk771\n",
      "pearson: 0.592 \n",
      "spearman: 0.613\n",
      "\n",
      "missing words: 0 out of 771\n",
      "evaluating conceptnet against MTurk771\n",
      "pearson: 0.789 \n",
      "spearman: 0.820\n",
      "\n",
      "missing words: 2 out of 771\n",
      "evaluating wordnet against MTurk771\n",
      "pearson: 0.547 \n",
      "spearman: 0.556\n",
      "\n",
      "missing words: 0 out of 771\n",
      "evaluating bert against MTurk771\n",
      "pearson: 0.643 \n",
      "spearman: 0.669\n",
      "\n",
      "missing words: 0 out of 771\n",
      "evaluating gpt2 against MTurk771\n",
      "pearson: 0.651 \n",
      "spearman: 0.677\n",
      "\n",
      "missing words: 0 out of 771\n",
      "evaluating electra against MTurk771\n",
      "pearson: 0.664 \n",
      "spearman: 0.688\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in sim.models:\n",
    "    sim.model_vs_data(model,'MTurk771', layer=0, comp_method='decontext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "65735e10-2db1-4826-9ea1-40eafe46f5ae",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RW loaded\n",
      "missing words: 438 out of 2034\n",
      "evaluating CW_vectors against RW\n",
      "pearson: 0.354 \n",
      "spearman: 0.363\n",
      "\n",
      "missing words: 833 out of 2034\n",
      "evaluating dm_vectors against RW\n",
      "pearson: 0.299 \n",
      "spearman: 0.277\n",
      "\n",
      "missing words: 351 out of 2034\n",
      "evaluating gensim_cbow against RW\n",
      "pearson: 0.459 \n",
      "spearman: 0.490\n",
      "\n",
      "missing words: 250 out of 2034\n",
      "evaluating gensim_skip against RW\n",
      "pearson: 0.456 \n",
      "spearman: 0.492\n",
      "\n",
      "missing words: 20 out of 2034\n",
      "evaluating word2vec_skip against RW\n",
      "pearson: 0.430 \n",
      "spearman: 0.425\n",
      "\n",
      "missing words: 12 out of 2034\n",
      "evaluating glove against RW\n",
      "pearson: 0.449 \n",
      "spearman: 0.461\n",
      "\n",
      "missing words: 250 out of 2034\n",
      "evaluating fasttext_wiki+giga against RW\n",
      "pearson: 0.469 \n",
      "spearman: 0.497\n",
      "\n",
      "missing words: 136 out of 2034\n",
      "evaluating lexvec against RW\n",
      "pearson: 0.463 \n",
      "spearman: 0.490\n",
      "\n",
      "missing words: 0 out of 2034\n",
      "evaluating elmo against RW\n",
      "pearson: 0.461 \n",
      "spearman: 0.470\n",
      "\n",
      "missing words: 57 out of 2034\n",
      "evaluating conceptnet against RW\n",
      "pearson: 0.611 \n",
      "spearman: 0.632\n",
      "\n",
      "missing words: 1470 out of 2034\n",
      "evaluating wordnet against RW\n",
      "pearson: 0.402 \n",
      "spearman: 0.433\n",
      "\n",
      "missing words: 0 out of 2034\n",
      "evaluating bert against RW\n",
      "pearson: 0.308 \n",
      "spearman: 0.338\n",
      "\n",
      "missing words: 0 out of 2034\n",
      "evaluating gpt2 against RW\n",
      "pearson: 0.365 \n",
      "spearman: 0.409\n",
      "\n",
      "missing words: 0 out of 2034\n",
      "evaluating electra against RW\n",
      "pearson: 0.337 \n",
      "spearman: 0.378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in sim.models:\n",
    "    sim.model_vs_data(model,'RW', layer=0, comp_method='decontext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8291bc77-2691-42e3-83a8-a487f5e2096b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEN loaded\n",
      "missing words: 1 out of 3000\n",
      "evaluating CW_vectors against MEN\n",
      "pearson: 0.564 \n",
      "spearman: 0.569\n",
      "\n",
      "missing words: 0 out of 3000\n",
      "evaluating dm_vectors against MEN\n",
      "pearson: 0.365 \n",
      "spearman: 0.276\n",
      "\n",
      "missing words: 3 out of 3000\n",
      "evaluating gensim_cbow against MEN\n",
      "pearson: 0.700 \n",
      "spearman: 0.705\n",
      "\n",
      "missing words: 5 out of 3000\n",
      "evaluating gensim_skip against MEN\n",
      "pearson: 0.724 \n",
      "spearman: 0.727\n",
      "\n",
      "missing words: 0 out of 3000\n",
      "evaluating word2vec_skip against MEN\n",
      "pearson: 0.739 \n",
      "spearman: 0.740\n",
      "\n",
      "missing words: 0 out of 3000\n",
      "evaluating glove against MEN\n",
      "pearson: 0.801 \n",
      "spearman: 0.802\n",
      "\n",
      "missing words: 5 out of 3000\n",
      "evaluating fasttext_wiki+giga against MEN\n",
      "pearson: 0.738 \n",
      "spearman: 0.738\n",
      "\n",
      "missing words: 0 out of 3000\n",
      "evaluating lexvec against MEN\n",
      "pearson: 0.737 \n",
      "spearman: 0.751\n",
      "\n",
      "missing words: 0 out of 3000\n",
      "evaluating elmo against MEN\n",
      "pearson: 0.623 \n",
      "spearman: 0.644\n",
      "\n",
      "missing words: 0 out of 3000\n",
      "evaluating conceptnet against MEN\n",
      "pearson: 0.847 \n",
      "spearman: 0.866\n",
      "\n",
      "missing words: 1226 out of 3000\n",
      "evaluating wordnet against MEN\n",
      "pearson: 0.449 \n",
      "spearman: 0.436\n",
      "\n",
      "missing words: 0 out of 3000\n",
      "evaluating bert against MEN\n",
      "pearson: 0.626 \n",
      "spearman: 0.659\n",
      "\n",
      "missing words: 0 out of 3000\n",
      "evaluating gpt2 against MEN\n",
      "pearson: 0.634 \n",
      "spearman: 0.644\n",
      "\n",
      "missing words: 0 out of 3000\n",
      "evaluating electra against MEN\n",
      "pearson: 0.681 \n",
      "spearman: 0.715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in sim.models:\n",
    "    sim.model_vs_data(model,'MEN', layer=0, comp_method='decontext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "d7c1f40a-c953-4be3-8bcb-b4049d77fd4d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimLex loaded\n",
      "missing words: 1 out of 999\n",
      "evaluating CW_vectors against SimLex\n",
      "pearson: 0.285 \n",
      "spearman: 0.266\n",
      "\n",
      "missing words: 2 out of 999\n",
      "evaluating gensim_cbow against SimLex\n",
      "pearson: 0.443 \n",
      "spearman: 0.432\n",
      "\n",
      "missing words: 3 out of 999\n",
      "evaluating gensim_skip against SimLex\n",
      "pearson: 0.400 \n",
      "spearman: 0.393\n",
      "\n",
      "missing words: 0 out of 999\n",
      "evaluating word2vec_skip against SimLex\n",
      "pearson: 0.360 \n",
      "spearman: 0.337\n",
      "\n",
      "missing words: 0 out of 999\n",
      "evaluating glove against SimLex\n",
      "pearson: 0.436 \n",
      "spearman: 0.408\n",
      "\n",
      "missing words: 3 out of 999\n",
      "evaluating fasttext_wiki+giga against SimLex\n",
      "pearson: 0.401 \n",
      "spearman: 0.389\n",
      "\n",
      "missing words: 1 out of 999\n",
      "evaluating lexvec against SimLex\n",
      "pearson: 0.392 \n",
      "spearman: 0.384\n",
      "\n",
      "missing words: 0 out of 999\n",
      "evaluating elmo against SimLex\n",
      "pearson: 0.420 \n",
      "spearman: 0.428\n",
      "\n",
      "missing words: 0 out of 999\n",
      "evaluating conceptnet against SimLex\n",
      "pearson: 0.646 \n",
      "spearman: 0.627\n",
      "\n",
      "missing words: 2 out of 999\n",
      "evaluating wordnet against SimLex\n",
      "pearson: 0.525 \n",
      "spearman: 0.523\n",
      "\n",
      "missing words: 0 out of 999\n",
      "evaluating bert against SimLex\n",
      "pearson: 0.475 \n",
      "spearman: 0.494\n",
      "\n",
      "missing words: 0 out of 999\n",
      "evaluating gpt2 against SimLex\n",
      "pearson: 0.492 \n",
      "spearman: 0.480\n",
      "\n",
      "missing words: 0 out of 999\n",
      "evaluating electra against SimLex\n",
      "pearson: 0.482 \n",
      "spearman: 0.479\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in sim.models:\n",
    "    sim.model_vs_data(model,'SimLex', layer=0, comp_method='decontext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4796875a-bddc-49d9-8bad-31b3577aeba8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing words: 0 out of 666\n",
      "evaluating CW_vectors against SimLexN\n",
      "pearson: 0.334 \n",
      "spearman: 0.311\n",
      "\n",
      "missing words: 5 out of 666\n",
      "evaluating dm_vectors against SimLexN\n",
      "pearson: 0.299 \n",
      "spearman: 0.277\n",
      "\n",
      "missing words: 0 out of 666\n",
      "evaluating gensim_cbow against SimLexN\n",
      "pearson: 0.495 \n",
      "spearman: 0.481\n",
      "\n",
      "missing words: 0 out of 666\n",
      "evaluating gensim_skip against SimLexN\n",
      "pearson: 0.409 \n",
      "spearman: 0.395\n",
      "\n",
      "missing words: 0 out of 666\n",
      "evaluating word2vec_skip against SimLexN\n",
      "pearson: 0.410 \n",
      "spearman: 0.381\n",
      "\n",
      "missing words: 0 out of 666\n",
      "evaluating glove against SimLexN\n",
      "pearson: 0.467 \n",
      "spearman: 0.428\n",
      "\n",
      "missing words: 0 out of 666\n",
      "evaluating fasttext_wiki+giga against SimLexN\n",
      "pearson: 0.416 \n",
      "spearman: 0.398\n",
      "\n",
      "missing words: 0 out of 666\n",
      "evaluating lexvec against SimLexN\n",
      "pearson: 0.423 \n",
      "spearman: 0.424\n",
      "\n",
      "missing words: 0 out of 666\n",
      "evaluating elmo against SimLexN\n",
      "pearson: 0.448 \n",
      "spearman: 0.460\n",
      "\n",
      "missing words: 0 out of 666\n",
      "evaluating conceptnet against SimLexN\n",
      "pearson: 0.642 \n",
      "spearman: 0.619\n",
      "\n",
      "missing words: 0 out of 666\n",
      "evaluating wordnet against SimLexN\n",
      "pearson: 0.503 \n",
      "spearman: 0.527\n",
      "\n",
      "missing words: 0 out of 666\n",
      "evaluating bert against SimLexN\n",
      "pearson: 0.460 \n",
      "spearman: 0.497\n",
      "\n",
      "missing words: 0 out of 666\n",
      "evaluating gpt2 against SimLexN\n",
      "pearson: 0.491 \n",
      "spearman: 0.502\n",
      "\n",
      "missing words: 0 out of 666\n",
      "evaluating electra against SimLexN\n",
      "pearson: 0.488 \n",
      "spearman: 0.497\n",
      "\n",
      "missing words: 665 out of 666\n",
      "evaluating bert_context against SimLexN\n",
      "pearson: nan \n",
      "spearman: nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\numpy\\lib\\function_base.py:2634: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n",
      "D:\\Anaconda\\lib\\site-packages\\numpy\\lib\\function_base.py:2493: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n",
      "D:\\Anaconda\\lib\\site-packages\\numpy\\lib\\function_base.py:2493: RuntimeWarning: invalid value encountered in multiply\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    }
   ],
   "source": [
    "for model in sim.models:\n",
    "    sim.model_vs_data(model,'SimLexN', layer=0, comp_method='decontext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "50f2bbe3-b2e9-476f-b01e-fa84b550d4d6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing words: 1 out of 222\n",
      "evaluating CW_vectors against SimLexV\n",
      "pearson: 0.159 \n",
      "spearman: 0.147\n",
      "\n",
      "missing words: 0 out of 222\n",
      "evaluating dm_vectors against SimLexV\n",
      "pearson: 0.070 \n",
      "spearman: 0.061\n",
      "\n",
      "missing words: 2 out of 222\n",
      "evaluating gensim_cbow against SimLexV\n",
      "pearson: 0.269 \n",
      "spearman: 0.243\n",
      "\n",
      "missing words: 3 out of 222\n",
      "evaluating gensim_skip against SimLexV\n",
      "pearson: 0.305 \n",
      "spearman: 0.290\n",
      "\n",
      "missing words: 0 out of 222\n",
      "evaluating word2vec_skip against SimLexV\n",
      "pearson: 0.154 \n",
      "spearman: 0.145\n",
      "\n",
      "missing words: 0 out of 222\n",
      "evaluating glove against SimLexV\n",
      "pearson: 0.219 \n",
      "spearman: 0.196\n",
      "\n",
      "missing words: 3 out of 222\n",
      "evaluating fasttext_wiki+giga against SimLexV\n",
      "pearson: 0.279 \n",
      "spearman: 0.261\n",
      "\n",
      "missing words: 1 out of 222\n",
      "evaluating lexvec against SimLexV\n",
      "pearson: 0.226 \n",
      "spearman: 0.212\n",
      "\n",
      "missing words: 0 out of 222\n",
      "evaluating elmo against SimLexV\n",
      "pearson: 0.392 \n",
      "spearman: 0.374\n",
      "\n",
      "missing words: 0 out of 222\n",
      "evaluating conceptnet against SimLexV\n",
      "pearson: 0.579 \n",
      "spearman: 0.533\n",
      "\n",
      "missing words: 0 out of 222\n",
      "evaluating wordnet against SimLexV\n",
      "pearson: 0.485 \n",
      "spearman: 0.457\n",
      "\n",
      "missing words: 0 out of 222\n",
      "evaluating bert against SimLexV\n",
      "pearson: 0.455 \n",
      "spearman: 0.430\n",
      "\n",
      "missing words: 0 out of 222\n",
      "evaluating gpt2 against SimLexV\n",
      "pearson: 0.424 \n",
      "spearman: 0.376\n",
      "\n",
      "missing words: 0 out of 222\n",
      "evaluating electra against SimLexV\n",
      "pearson: 0.393 \n",
      "spearman: 0.373\n",
      "\n",
      "missing words: 30 out of 222\n",
      "evaluating bert_context against SimLexV\n",
      "pearson: 0.353 \n",
      "spearman: 0.327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in sim.models:\n",
    "    sim.model_vs_data(model,'SimLexV', layer=0, comp_method='decontext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d59e20b-ad69-4151-9192-52a1b8f57ef9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing words: 0 out of 111\n",
      "evaluating CW_vectors against SimLexA\n",
      "pearson: 0.246 \n",
      "spearman: 0.263\n",
      "\n",
      "missing words: 0 out of 111\n",
      "evaluating dm_vectors against SimLexA\n",
      "pearson: 0.357 \n",
      "spearman: 0.347\n",
      "\n",
      "missing words: 0 out of 111\n",
      "evaluating gensim_cbow against SimLexA\n",
      "pearson: 0.514 \n",
      "spearman: 0.526\n",
      "\n",
      "missing words: 0 out of 111\n",
      "evaluating gensim_skip against SimLexA\n",
      "pearson: 0.529 \n",
      "spearman: 0.546\n",
      "\n",
      "missing words: 0 out of 111\n",
      "evaluating word2vec_skip against SimLexA\n",
      "pearson: 0.434 \n",
      "spearman: 0.456\n",
      "\n",
      "missing words: 0 out of 111\n",
      "evaluating glove against SimLexA\n",
      "pearson: 0.612 \n",
      "spearman: 0.622\n",
      "\n",
      "missing words: 0 out of 111\n",
      "evaluating fasttext_wiki+giga against SimLexA\n",
      "pearson: 0.530 \n",
      "spearman: 0.545\n",
      "\n",
      "missing words: 0 out of 111\n",
      "evaluating lexvec against SimLexA\n",
      "pearson: 0.495 \n",
      "spearman: 0.518\n",
      "\n",
      "missing words: 0 out of 111\n",
      "evaluating elmo against SimLexA\n",
      "pearson: 0.394 \n",
      "spearman: 0.399\n",
      "\n",
      "missing words: 0 out of 111\n",
      "evaluating conceptnet against SimLexA\n",
      "pearson: 0.775 \n",
      "spearman: 0.757\n",
      "\n",
      "missing words: 2 out of 111\n",
      "evaluating wordnet against SimLexA\n",
      "pearson: 0.676 \n",
      "spearman: 0.623\n",
      "\n",
      "missing words: 0 out of 111\n",
      "evaluating bert against SimLexA\n",
      "pearson: 0.586 \n",
      "spearman: 0.584\n",
      "\n",
      "missing words: 0 out of 111\n",
      "evaluating gpt2 against SimLexA\n",
      "pearson: 0.608 \n",
      "spearman: 0.611\n",
      "\n",
      "missing words: 0 out of 111\n",
      "evaluating electra against SimLexA\n",
      "pearson: 0.584 \n",
      "spearman: 0.581\n",
      "\n",
      "missing words: 111 out of 111\n",
      "evaluating bert_context against SimLexA\n",
      "pearson: nan \n",
      "spearman: nan\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\numpy\\lib\\function_base.py:380: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "D:\\Anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:180: RuntimeWarning: invalid value encountered in true_divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "for model in sim.models:\n",
    "    sim.model_vs_data(model,'SimLexA', layer=0, comp_method='decontext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "beb9c2e3-4b04-4f6a-b725-897752e95709",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimVerb loaded\n",
      "missing words: 55 out of 3500\n",
      "evaluating CW_vectors against SimVerb\n",
      "pearson: 0.169 \n",
      "spearman: 0.163\n",
      "\n",
      "missing words: 15 out of 3500\n",
      "evaluating dm_vectors against SimVerb\n",
      "pearson: 0.172 \n",
      "spearman: 0.140\n",
      "\n",
      "missing words: 27 out of 3500\n",
      "evaluating gensim_cbow against SimVerb\n",
      "pearson: 0.330 \n",
      "spearman: 0.322\n",
      "\n",
      "missing words: 34 out of 3500\n",
      "evaluating gensim_skip against SimVerb\n",
      "pearson: 0.332 \n",
      "spearman: 0.319\n",
      "\n",
      "missing words: 0 out of 3500\n",
      "evaluating word2vec_skip against SimVerb\n",
      "pearson: 0.229 \n",
      "spearman: 0.218\n",
      "\n",
      "missing words: 0 out of 3500\n",
      "evaluating glove against SimVerb\n",
      "pearson: 0.294 \n",
      "spearman: 0.283\n",
      "\n",
      "missing words: 34 out of 3500\n",
      "evaluating fasttext_wiki+giga against SimVerb\n",
      "pearson: 0.322 \n",
      "spearman: 0.310\n",
      "\n",
      "missing words: 2 out of 3500\n",
      "evaluating lexvec against SimVerb\n",
      "pearson: 0.275 \n",
      "spearman: 0.279\n",
      "\n",
      "missing words: 0 out of 3500\n",
      "evaluating elmo against SimVerb\n",
      "pearson: 0.352 \n",
      "spearman: 0.342\n",
      "\n",
      "missing words: 0 out of 3500\n",
      "evaluating conceptnet against SimVerb\n",
      "pearson: 0.588 \n",
      "spearman: 0.572\n",
      "\n",
      "missing words: 1759 out of 3500\n",
      "evaluating wordnet against SimVerb\n",
      "pearson: 0.504 \n",
      "spearman: 0.486\n",
      "\n",
      "missing words: 0 out of 3500\n",
      "evaluating bert against SimVerb\n",
      "pearson: 0.334 \n",
      "spearman: 0.317\n",
      "\n",
      "missing words: 0 out of 3500\n",
      "evaluating gpt2 against SimVerb\n",
      "pearson: 0.350 \n",
      "spearman: 0.342\n",
      "\n",
      "missing words: 0 out of 3500\n",
      "evaluating electra against SimVerb\n",
      "pearson: 0.364 \n",
      "spearman: 0.361\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in sim.models:\n",
    "    sim.model_vs_data(model,'SimVerb', layer=0, comp_method='decontext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c98a798e-1d8e-4045-81cc-34972bde9e90",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimVerb_na loaded\n",
      "missing words: 54 out of 3367\n",
      "evaluating CW_vectors against SimVerb_na\n",
      "pearson: 0.210 \n",
      "spearman: 0.206\n",
      "\n",
      "missing words: 26 out of 3367\n",
      "evaluating gensim_cbow against SimVerb_na\n",
      "pearson: 0.376 \n",
      "spearman: 0.365\n",
      "\n",
      "missing words: 33 out of 3367\n",
      "evaluating gensim_skip against SimVerb_na\n",
      "pearson: 0.378 \n",
      "spearman: 0.362\n",
      "\n",
      "missing words: 0 out of 3367\n",
      "evaluating word2vec_skip against SimVerb_na\n",
      "pearson: 0.269 \n",
      "spearman: 0.256\n",
      "\n",
      "missing words: 0 out of 3367\n",
      "evaluating glove against SimVerb_na\n",
      "pearson: 0.339 \n",
      "spearman: 0.329\n",
      "\n",
      "missing words: 33 out of 3367\n",
      "evaluating fasttext_wiki+giga against SimVerb_na\n",
      "pearson: 0.368 \n",
      "spearman: 0.353\n",
      "\n",
      "missing words: 2 out of 3367\n",
      "evaluating lexvec against SimVerb_na\n",
      "pearson: 0.329 \n",
      "spearman: 0.329\n",
      "\n",
      "missing words: 0 out of 3367\n",
      "evaluating elmo against SimVerb_na\n",
      "pearson: 0.393 \n",
      "spearman: 0.378\n",
      "\n",
      "missing words: 0 out of 3367\n",
      "evaluating conceptnet against SimVerb_na\n",
      "pearson: 0.631 \n",
      "spearman: 0.619\n",
      "\n",
      "missing words: 1709 out of 3367\n",
      "evaluating wordnet against SimVerb_na\n",
      "pearson: 0.553 \n",
      "spearman: 0.538\n",
      "\n",
      "missing words: 0 out of 3367\n",
      "evaluating bert against SimVerb_na\n",
      "pearson: 0.378 \n",
      "spearman: 0.363\n",
      "\n",
      "missing words: 0 out of 3367\n",
      "evaluating gpt2 against SimVerb_na\n",
      "pearson: 0.392 \n",
      "spearman: 0.383\n",
      "\n",
      "missing words: 0 out of 3367\n",
      "evaluating electra against SimVerb_na\n",
      "pearson: 0.414 \n",
      "spearman: 0.410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in sim.models:\n",
    "    sim.model_vs_data(model,'SimVerb_na', layer=0, comp_method='decontext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "049ecac7-501d-4b6d-82e3-bde979b83f28",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing words: 60 out of 3341\n",
      "evaluating CW_vectors against SimVerb_nax\n",
      "pearson: 0.212 \n",
      "spearman: 0.206\n",
      "\n",
      "missing words: 29 out of 3341\n",
      "evaluating dm_vectors against SimVerb_nax\n",
      "pearson: 0.208 \n",
      "spearman: 0.161\n",
      "\n",
      "missing words: 12 out of 3341\n",
      "evaluating gensim_cbow against SimVerb_nax\n",
      "pearson: 0.382 \n",
      "spearman: 0.371\n",
      "\n",
      "missing words: 19 out of 3341\n",
      "evaluating gensim_skip against SimVerb_nax\n",
      "pearson: 0.382 \n",
      "spearman: 0.365\n",
      "\n",
      "missing words: 0 out of 3341\n",
      "evaluating word2vec_skip against SimVerb_nax\n",
      "pearson: 0.271 \n",
      "spearman: 0.259\n",
      "\n",
      "missing words: 0 out of 3341\n",
      "evaluating glove against SimVerb_nax\n",
      "pearson: 0.343 \n",
      "spearman: 0.332\n",
      "\n",
      "missing words: 19 out of 3341\n",
      "evaluating fasttext_wiki+giga against SimVerb_nax\n",
      "pearson: 0.372 \n",
      "spearman: 0.357\n",
      "\n",
      "missing words: 2 out of 3341\n",
      "evaluating lexvec against SimVerb_nax\n",
      "pearson: 0.332 \n",
      "spearman: 0.332\n",
      "\n",
      "missing words: 0 out of 3341\n",
      "evaluating elmo against SimVerb_nax\n",
      "pearson: 0.394 \n",
      "spearman: 0.379\n",
      "\n",
      "missing words: 0 out of 3341\n",
      "evaluating conceptnet against SimVerb_nax\n",
      "pearson: 0.633 \n",
      "spearman: 0.622\n",
      "\n",
      "missing words: 1741 out of 3341\n",
      "evaluating wordnet against SimVerb_nax\n",
      "pearson: 0.559 \n",
      "spearman: 0.547\n",
      "\n",
      "missing words: 0 out of 3341\n",
      "evaluating bert against SimVerb_nax\n",
      "pearson: 0.379 \n",
      "spearman: 0.363\n",
      "\n",
      "missing words: 0 out of 3341\n",
      "evaluating gpt2 against SimVerb_nax\n",
      "pearson: 0.394 \n",
      "spearman: 0.385\n",
      "\n",
      "missing words: 0 out of 3341\n",
      "evaluating electra against SimVerb_nax\n",
      "pearson: 0.415 \n",
      "spearman: 0.411\n",
      "\n",
      "missing words: 4 out of 3341\n",
      "evaluating bert_context against SimVerb_nax\n",
      "pearson: 0.450 \n",
      "spearman: 0.444\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in sim.models:\n",
    "    sim.model_vs_data(model,'SimVerb_nax', layer=0, comp_method='decontext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facf7196-9d73-4181-ade2-fd6fdce25296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
