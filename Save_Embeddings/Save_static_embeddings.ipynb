{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c89405b-8033-44e2-9bcf-364ca43dc4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to extract embeddings from static word embedding models\n",
    "## James Fodor 2022\n",
    "## Python 3.8\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set numpy display properties needed for printing to file\n",
    "np.set_printoptions(precision=5, threshold=10000, linewidth=10000, suppress=True, floatmode='fixed')\n",
    "\n",
    "# Define base path location for data\n",
    "path_base = 'D:\\Study and Projects\\School Work\\Year 25 - PhD 1\\Data\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46969e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Key functions\n",
    "\n",
    "# Function to load a specific word embedding model\n",
    "def import_model(file_loc, vocab, full_import=False):\n",
    "    \"\"\" string -> None\n",
    "    Imports an embedding model, storing it in the model_embed_storage dictionary.\n",
    "    \"\"\"\n",
    "        \n",
    "    # open relevant file\n",
    "    filename = path_base+file_loc\n",
    "    with open(filename) as file:\n",
    "        lines = [line.rstrip('\\n') for line in file]\n",
    "\n",
    "    model_dict = {} # create word dictionary for specific model\n",
    "    for line in lines:\n",
    "        word_list = line.split()\n",
    "        word = word_list[0]\n",
    "        if full_import==False and word in vocab: # only  words for testing if full_import==False\n",
    "            embedding_list = [float(x) for x in word_list[1:-1]] # store embeddings\n",
    "            embedding_np = np.array(embedding_list)\n",
    "            model_dict[word] = embedding_np\n",
    "        elif full_import==True: # this will import all words in the vocab set, not just those for testing\n",
    "            embedding_list = [float(x) for x in word_list[1:-1]] # store embeddings\n",
    "            embedding_np = np.array(embedding_list)\n",
    "            model_dict[word] = embedding_np\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return model_dict # store model dictionary in the models dictionary\n",
    "    \n",
    "# Load word similarity dataset\n",
    "def load_sim_dataset(dataset):\n",
    "    \"\"\" str -> (list_str, np_array)\n",
    "    Loads a dataset of word similarities, returning the word pairs and similarity ratings.\n",
    "    \"\"\"\n",
    "    filename = 'Vocab_lists/'+dataset+'.txt'\n",
    "    with open(filename) as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    wordpairs = [None]*len(lines) # initialise storage\n",
    "    ratings = [None]*len(lines)\n",
    "    i=0\n",
    "    for line in lines:\n",
    "        line = line.strip() # remove new line chars\n",
    "        wordpairs[i] = line.split() # split at any whitespace chars\n",
    "        ratings[i] = float(wordpairs[i][2])\n",
    "        i=i+1\n",
    "    ratings = np.array(ratings)\n",
    "\n",
    "    return wordpairs, ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3e732d4-f108-45d4-8290-9fca5fcf343c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN-SIMLEX-999-VERB vocab loaded\n",
      "170 words\n"
     ]
    }
   ],
   "source": [
    "# Load vocab set\n",
    "dataset_name = 'EN-SIMLEX-999-VERB'\n",
    "dataset, _ = load_sim_dataset(dataset_name)\n",
    "vocab = []\n",
    "for word_pair in dataset:\n",
    "    vocab.append(word_pair[0])\n",
    "    vocab.append(word_pair[1])\n",
    "vocab_set = list(set(vocab))\n",
    "vocab_set.sort()\n",
    "print(dataset_name+' vocab loaded')\n",
    "print(str(len(vocab_set))+' words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b67da289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word embeddings for set vocabulary\n",
    "embed_file = 'Word Embeddings//WordNet Word Embeddings//wn2vec.txt'\n",
    "embeddings = import_model(embed_file, vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "985bd6a4-1891-40f5-b877-3c86b1d07235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special code for certain models with unusual formatting\n",
    "\n",
    "# Special code for Gensim Skipgram BNC\n",
    "# data = np.loadtxt(embedding_loc, dtype = str) # special code for loading Gensim SKipgram BNC (regular code not working for some reason)\n",
    "# embedding_model = pd.DataFrame(data[:,1:].astype(float), index = data[:,0])\n",
    "# embedding_model.index = [x.replace('::',' ') for x in embedding_model.index.values]\n",
    "\n",
    "# Special code for processing BNC data; remove _ and :: annotations\n",
    "# embedding_model = pd.read_table(embedding_loc, index_col=0, header=None, delim_whitespace=True, quoting=csv.QUOTE_NONE, skip_blank_lines=True)\n",
    "# embedding_model.index = [x.split('_')[0].replace('::',' ') for x in embedding_model.index.values] \n",
    "# embedding_model.index = remove_trailing_chars(embedding_model) # needed to remove trailing characters when present\n",
    "\n",
    "# Code for removing trailing characters from words in index values; input is pandas df; needed for some models only\n",
    "# def remove_trailing_chars(embedding_model):\n",
    "#     new_indices = []\n",
    "#     for word in embedding_model.index.values:\n",
    "#         new_indices.append(word[0:-2])\n",
    "#     return(new_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa989270-958d-4d5e-bf4f-6ed7d67c36f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings to new file\n",
    "save_path = 'wordnet.txt' # specify name of save file\n",
    "with open(save_path, \"a\", encoding='utf-8') as file:\n",
    "    for word in vocab_set:\n",
    "        try:\n",
    "            embedding = embeddings[word]\n",
    "            file.writelines(word+' '+str(embedding)[1:-1]) # remove brackets\n",
    "            file.write('\\n')\n",
    "        except:\n",
    "            continue\n",
    "            print('missing '+word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
