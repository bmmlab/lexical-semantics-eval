{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup, Tag, NavigableString\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.edge.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "options = Options()\n",
    "driver_path = Service('D:\\Downloads\\Archive\\edgedriver_win64\\msedgedriver.exe') # needed for selenium\n",
    "options.add_argument(\"--headless\") \n",
    "driver = webdriver.Edge(service=driver_path, options=options)\n",
    "file_path = 'D:\\Study and Projects\\School Work\\Year 25 - PhD 1\\Data\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word similarity dataset\n",
    "def load_sim_dataset(model):\n",
    "    path = file_path+'Word Similarity Data\\Word Similarities Final\\\\'\n",
    "    filename = path+model+'.txt'\n",
    "    with open(filename) as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    wordpairs = [None]*len(lines) # initialise storage\n",
    "    ratings = [None]*len(lines)\n",
    "    i=0\n",
    "    for line in lines:\n",
    "        line = line.strip() # remove new line chars\n",
    "        wordpairs[i] = line.split() # split at any whitespace chars\n",
    "        ratings[i] = float(wordpairs[i][2])\n",
    "        i=i+1\n",
    "    ratings = np.array(ratings)\n",
    "\n",
    "    return(wordpairs, ratings)\n",
    "\n",
    "# Open web page for a given url\n",
    "def get_web_page(url):\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, 'lxml')\n",
    "    part_of_speech = soup.find_all(class_=\"pos\")\n",
    "    all_results = soup.find_all(class_=\"sense\")\n",
    "    return(all_results, part_of_speech[0].text)\n",
    "\n",
    "\n",
    "def extract_sense_examples(raw_html):\n",
    "    sense_dict = {}\n",
    "    for index, result in enumerate(raw_html):\n",
    "        examples_list = []\n",
    "        examples = result.find_all(class_=\"x\")\n",
    "        for example in examples:\n",
    "            examples_list.append(example.text)\n",
    "        extra_examples = result.find_all(class_=\"unx\")\n",
    "        for example in extra_examples:\n",
    "            examples_list.append(example.text)\n",
    "        if len(result.find_all(class_=\"def\"))>0:\n",
    "            sense_dict[index+1, result.find_all(class_=\"def\")[0].text] = examples_list\n",
    "    return(sense_dict)\n",
    "\n",
    "\n",
    "def save_sense_examples(sense_dict, path):\n",
    "    for sense in sense_dict.keys():\n",
    "        sense_id = sense[0]\n",
    "        file_name = path+'Senses\\\\'+word+'_'+str(sense_id)+'.txt'\n",
    "        save_file = open(file_name, \"a\", encoding='utf-8')\n",
    "        i=0\n",
    "        for line in sense_dict[sense]:\n",
    "            save_file.writelines(line)\n",
    "            save_file.write('\\n')\n",
    "            i=i+1\n",
    "        save_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimVerb_mod vocab loaded\n",
      "822 words\n"
     ]
    }
   ],
   "source": [
    "# Load vocab set\n",
    "dataset_name = 'SimVerb_mod'\n",
    "dataset, _ = load_sim_dataset('EN-SimVerb-3200-mod-uk')\n",
    "vocab = []\n",
    "for word_pair in dataset:\n",
    "    vocab.append(word_pair[0])\n",
    "    vocab.append(word_pair[1])\n",
    "vocab_set = list(set(vocab))\n",
    "vocab_set.sort()\n",
    "print(dataset_name+' vocab loaded')\n",
    "print(str(len(vocab_set))+' words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract sense examples from the Oxford Learners Dictionary website\n",
    "for word in vocab_set:\n",
    "    url = 'https://www.oxfordlearnersdictionaries.com/definition/english/'+word+'_1'\n",
    "    all_results, part_of_speech = get_web_page(url)\n",
    "    if part_of_speech=='verb' or part_of_speech=='linking verb' or word=='pup': # exclude weird word 'pup'\n",
    "        sense_dict = extract_sense_examples(all_results)\n",
    "    else: # try another number if the first one isn't a verb\n",
    "        url = 'https://www.oxfordlearnersdictionaries.com/definition/english/'+word+'_2'\n",
    "        all_results, part_of_speech = get_web_page(url)\n",
    "        sense_dict = extract_sense_examples(all_results)\n",
    "    save_sense_examples(sense_dict,file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "88279d2366fe020547cde40dd65aa0e3aa662a6ec1f3ca12d88834876c85e1a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
